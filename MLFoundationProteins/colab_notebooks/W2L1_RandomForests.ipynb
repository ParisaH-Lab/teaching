{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W2L1_RandomForests.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ul_uYNvFteJX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest**\n",
        "<font color='grey' size='1.5'> Created by Parisa Hosseinzadeh for *Machine learning for proteins*, Spring 2022. \n",
        "\n",
        "Today, we will work on decision trees and random forests. The test case we will be using today is the *Pima Indians diabetes* set from [Kaggle](https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv?resource=download). \n",
        "\n",
        "Here is the description of the dataset from the website:\n",
        "\n",
        "This dataset describes the medical records for Pima Indians\n",
        "and whether or not each patient will have an onset of diabetes within \fve years.\n",
        "\n",
        "Fields description follow:\n",
        "\n",
        "- **preg** = Number of times pregnant\n",
        "- **plas** = Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "- **pres** = Diastolic blood pressure (mm Hg)\n",
        "- **skin** = Triceps skin fold thickness (mm)\n",
        "- **test** = 2-Hour serum insulin (mu U/ml)\n",
        "- **mass** = Body mass index (weight in kg/(height in m)^2)\n",
        "- **pedi** = Diabetes pedigree function\n",
        "- **age** = Age (years)\n",
        "- **class** = Class variable (1:tested positive for diabetes, 0: tested negative for diabetes)"
      ],
      "metadata": {
        "id": "QfvtVuKXdB60"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepratation"
      ],
      "metadata": {
        "id": "Ef0KaIsFdztL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading required modules"
      ],
      "metadata": {
        "id": "TOJjnWiOd4vo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "9iZIv51rPfAr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and preparing the dataset"
      ],
      "metadata": {
        "id": "cpFCjiX2d-Io"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# defining features/column names\n",
        "features = ['preg','plas','pres','skin',\n",
        "            'test','mass','pedi','age',\n",
        "            'class']\n",
        "# loading the dataset\n",
        "data = pd.read_csv('pima-indians-diabetes.csv', \n",
        "                   header=0,\n",
        "                   names=features)\n",
        "# viewing the top 5 rows\n",
        "data.head()"
      ],
      "metadata": {
        "id": "UzyL5ON-Qwzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at feature distribution\n",
        "data.hist(bins=50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "HYJxuuRsmcyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how many samples we have in each category\n",
        "print ('class 0 =', len(data[data['class'] == 0]))\n",
        "print ('class 1 =', len(data[data['class'] == 1]))"
      ],
      "metadata": {
        "id": "3qAdufJDmj0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1. Time to exercise\n",
        "\n",
        "1. Based on what you see in the distributions, what cleaning processes you need for this data?\n",
        "2. What type of train/test split you will use for this dataset based on the numbers in each class?\n"
      ],
      "metadata": {
        "id": "KXEKaGZghM6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using what you learned from [last lecture](https://colab.research.google.com/drive/1nxtav8c-I2Qav3OlISkZky8WJ1WWdD2F?usp=sharing), perform the following:\n",
        "\n",
        "2. Create a stratified test/train split, with 10% of data on test.\n",
        "\n",
        "Note that for decision trees, scaling is not required as they use a threshold in the feature space."
      ],
      "metadata": {
        "id": "Q8-mSBlAhb0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copy your data\n",
        "\n",
        "# perfomr splitting\n",
        "# call them train, test\n"
      ],
      "metadata": {
        "id": "KwktbnBvlsD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Decision Tree\n",
        "\n",
        "Let's first start with building a decision tree. There is a [DecisionTreeClassifier in scikit](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) but today, we will write our own code to get a better sense of how things work. "
      ],
      "metadata": {
        "id": "n-az6nQ5eDAx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing data and finding thresholds\n",
        "\n",
        "To make the process easier, we will first generate two subclass from our dataset: those with diabetes and those without. We then visualize these sets and choose our thresholds -- the best we can-- based on these."
      ],
      "metadata": {
        "id": "b2FImL_AgqSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting sub-dataframes for each class\n",
        "class_0 = train[train['class'] == 0]\n",
        "class_1 = train[train['class'] == 1]\n",
        "# making sure we're keeping the lengths\n",
        "print('class 0 has length ', len(class_0),\n",
        "      '\\n and class 1 has length', len(class_1),\n",
        "      '\\n and all data is of size ', len(data))"
      ],
      "metadata": {
        "id": "wbHM0rp4RKCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting distribution of features for class 0\n",
        "class_0.hist(bins=50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "i5AK-yTIVwyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting distribution of features for class 1\n",
        "class_1.hist(bins=50, figsize=(20,15))"
      ],
      "metadata": {
        "id": "-PEL2UNdcp-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Writing a very simple decision tree model\n",
        "\n",
        "Now, let's write a decision tree model. Each group has the choice of **up to 5** features to include for their decision tree. You will also need to define a threshold for each feature.\n",
        "\n",
        "Remeber, **class** is not a feature, but it's the labels."
      ],
      "metadata": {
        "id": "7LV_WuJ9hgl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2. Time to exercise\n",
        "\n",
        "1. What features did your group pick?\n",
        "2. What are the thresholds you're using?\n",
        "3. Which feature will be the top of your tree?"
      ],
      "metadata": {
        "id": "NhY-BNl6h_2C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's write the code. Your code is simply a nested if statement. Let's take a quick look at an example of how this works.\n",
        "\n",
        "Let's say you want to write a code that can classifies all the bold blue numbers from this list:\n",
        "\n",
        "<font color='blue'> 1 **0** 1 **1** <font color='red'> 0 **1** 1 0\n",
        "\n",
        "The pseudo-code looks something like this:\n",
        "\n",
        "is it blue:\n",
        "   if yes, is it bold:\n",
        "      if yes, label \"success\"\n",
        "\n",
        "The code then will look like this:\n",
        "\n",
        "```\n",
        "label = 0\n",
        "if color = blue:\n",
        "    if format = bold:\n",
        "        label = 1\n",
        "```\n",
        "\n",
        "*Question*: What would have happened if we started our classification by checking if it was bold first?\n",
        "\n",
        "Now work with your group to write the code for a very simple decision tree. I have added some suggestions of how to start below."
      ],
      "metadata": {
        "id": "DjS10W6wiMt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an list with the same length as\n",
        "# your dataset, filled with 0\n",
        "\n",
        "# write your nested if statements\n",
        "# when you get to the final interior if\n",
        "# set label at that location to be 1\n",
        "# you can iterate through a datafarame using\n",
        "# for i,r in df.iterrows()\n",
        "# where i is the index and r is the row\n",
        "# you can also access dataframe in a certain row i \n",
        "# by typing df.iloc[i]\n",
        "\n",
        "# add the predictions as a new column to your dataframe"
      ],
      "metadata": {
        "id": "9E_5RNePhgHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance analysis\n",
        "\n",
        "Now that you have a model, let's see how it is working. \n",
        "\n",
        "If you have time, try some other thresholds and see if you can improve your threshold."
      ],
      "metadata": {
        "id": "2ARQlwEwlKN2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3. Time to exercise\n",
        "\n",
        "In the cell below, write a code to calculate the precision, recall, and accuracy of your model on your test set.\n",
        "\n",
        "report these numbers"
      ],
      "metadata": {
        "id": "XcoyTnDFkOsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hint:\n",
        "# TP = # of 1s in prediction that are 1 in data\n",
        "# TN = # of 0s in prediction that are 0 in data\n",
        "# FP = # of 1s in prediction that are 0 in data\n",
        "# FN = # of 0s in prediction that are 1 in data\n",
        "\n",
        "# you can select a subset from a dataframe with conditions using:\n",
        "# new_df = df[df['c1'] == df['c2'] and ...]\n"
      ],
      "metadata": {
        "id": "6af6yYQphgJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional\n",
        "# Check to see if you can draw the confusion matrix \n",
        "# using either matplotlib or seaborn\n"
      ],
      "metadata": {
        "id": "kGpf9feTk6L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest\n",
        "\n",
        "Now that you have built some intuiton of a decision tree, let's work our way through testing a random forest."
      ],
      "metadata": {
        "id": "8P9BivlrlYKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Voting\n",
        "\n",
        "Let's see if voting helps with the performance of our decision trees using a small test set."
      ],
      "metadata": {
        "id": "hM4KQyKElg9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the test set (same way you loaded data)"
      ],
      "metadata": {
        "id": "bq8rZEhPnt27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict class values using your thresholds"
      ],
      "metadata": {
        "id": "n_ggPyDxnwjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4. Time to exercise\n",
        "\n",
        "1. What was your results?\n",
        "2. What was the result after voting?\n",
        "3. What is your conclusion?"
      ],
      "metadata": {
        "id": "RawC5tRrn0k0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RandomForestClassifier\n",
        "\n",
        "Now, let's use scikit's [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for properly classifying our data."
      ],
      "metadata": {
        "id": "jICBRmN5oESp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data to run\n",
        "# all features without class labels\n",
        "X = train[['preg','plas','pres','skin',\n",
        "            'test','mass','pedi','age']]\n",
        "# class labels\n",
        "labels = train['class']"
      ],
      "metadata": {
        "id": "DzjhTbYSo5Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# building the model\n",
        "random_forest = RandomForestClassifier(\n",
        "                      random_state= 42, # to make sure numbers are reproducible\n",
        "                      bootstrap=True, # To reduce correlation \n",
        "                      max_depth = 1, # number of features\n",
        "                      n_estimators = 20, # number of trees\n",
        "                      )"
      ],
      "metadata": {
        "id": "GoTNFmYJoe34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training\n",
        "random_forest.fit(X, labels)"
      ],
      "metadata": {
        "id": "Vtjl_USPs7ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's check which features where more important\n",
        "# check Important features\n",
        "feature_importances_df = pd.DataFrame(\n",
        "    {\"feature\": list(X.columns), \"importance\": random_forest.feature_importances_}\n",
        ").sort_values(\"importance\", ascending=False)\n",
        "\n",
        "# Display\n",
        "feature_importances_df"
      ],
      "metadata": {
        "id": "Rckakp0NQtWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q5. Time to exercise\n",
        "\n",
        "Now let's see how well your RF works on your test data. Report precision, recall, and accuracy."
      ],
      "metadata": {
        "id": "bA1Nu7crtCv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare test_X similarly to how you prepared X\n",
        "test_X = "
      ],
      "metadata": {
        "id": "0MbjPcj1tAgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# perform prediction\n",
        "predictions = random_forest.preedict(test_X)"
      ],
      "metadata": {
        "id": "N8WrChpitKjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate precision, recall and accuracy"
      ],
      "metadata": {
        "id": "L4bBhCpdtUtG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FYI: you can also get accuracy using this\n",
        "random_forest.score(test_X, test_labels)\n",
        "#or this\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"Accuracy:\", accuracy_score(labels, predictions))"
      ],
      "metadata": {
        "id": "x4iUAfL_po6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q6. Time to exercise\n",
        "\n",
        "Try reducing the depth from 5 to 1. What do you see?\n",
        "\n",
        "Try changing the number of estimators to 50 and 100. What do you see?"
      ],
      "metadata": {
        "id": "IYAmixDjuALA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# place holder for new models"
      ],
      "metadata": {
        "id": "OYNlbbU-uK7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optional:\n",
        "\n",
        "As we talked, random forests use a process called *bagging**. Thus, for each tree, a subset of input samples are not involved in training. Therefore, you can simply use that as a test for each tree and get an error called [out-of-the-bag error](https://en.wikipedia.org/wiki/Out-of-bag_error). This way, you won't need to split the data into train/test. \n",
        "\n",
        "The code below shows you how that is done."
      ],
      "metadata": {
        "id": "ul_uYNvFteJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# preparing data to run\n",
        "# all features without class labels\n",
        "X = data[['preg','plas','pres','skin',\n",
        "            'test','mass','pedi','age']]\n",
        "# class labels\n",
        "labels = data['class']"
      ],
      "metadata": {
        "id": "xC_puGAXt3_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# building the model\n",
        "random_forest = RandomForestClassifier(\n",
        "                      random_state= 42, \n",
        "                      bootstrap=True, \n",
        "                      oob_score=True,\n",
        "                      )"
      ],
      "metadata": {
        "id": "lL8zVa71sk_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_forest.fit(X, labels)\n",
        "oob_error = np.round(random_forest.oob_score_, 2)\n",
        "print( 'random forest with ', str(len(random_forest.estimators_)),\n",
        "       'trees has an OOB error of :', oob_error)"
      ],
      "metadata": {
        "id": "QYMtnWeMpgJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample answers to decision tree\n",
        "\n",
        "Below you may find some of the ways you can code your decision tree."
      ],
      "metadata": {
        "id": "_ox6muDGV-bJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# decision tree with 3 features\n",
        "# f1, f2, f3 are the features\n",
        "# t1, t2, t3 are the thresholds\n",
        "\n",
        "#setting the predictions to be all 0\n",
        "predictions = [0 for i in range(len(test))]\n",
        "\n",
        "j = 0\n",
        "#looping through all data to set those that are 1\n",
        "for id,sample in test.iterrows():\n",
        "  if sample['f1'] < t1:\n",
        "    if sample['f2'] > t2:\n",
        "      if sample['f3'] <= t3:\n",
        "        predictions[j] = 1\n",
        "  j += 1\n",
        "\n",
        "# adding predictions as a column to train\n",
        "test['prediction'] = predictions\n",
        "\n",
        "# to calculate accuracy:\n",
        "df_true = np.where(\n",
        "    test['class'] == test['prediction']\n",
        ")\n",
        "df_TP = np.where(\n",
        "    (\n",
        "        test['class'] == test['prediction']\n",
        "     ) & (\n",
        "        df['class'] == 1   \n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "28FvvO2lWFQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}