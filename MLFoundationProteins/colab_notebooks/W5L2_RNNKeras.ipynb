{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUGxU6pjjhn7"
      },
      "source": [
        "#**Implementing RNN architecture**\n",
        "<font color='grey' size='1.5'> Created by Parisa Hosseinzadeh for *Machine learning for proteins*, Spring 2022. The code in this exercise is adapted from [Victor Zhou](https://victorzhou.com/blog/keras-rnn-tutorial/)\n",
        "\n",
        "In today's in class activity, we will be building a recurrent neural net for sentiment analysis, in which we're reading sentences from movie reviews and want to predict whether it is a good review or not. This can be similar to reading in protein sequences and trying to predict whether they are an enzymes or not. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Vjc63u3AorO"
      },
      "source": [
        "## Step 1. Set up\n",
        "\n",
        "### 1.1. Set up directory\n",
        "\n",
        "Open the zip file and put it in your drive. It should contain these folders\n",
        "\n",
        "```\n",
        "dataset/\n",
        "  test/\n",
        "    neg/\n",
        "    pos/\n",
        "  train/\n",
        "    neg/\n",
        "    pos/\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFrpSpkHB25j"
      },
      "source": [
        "### 1.2. Mount google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOVsA2YTB5jE",
        "outputId": "4ee36b71-89d2-4797-ccd4-146a182c771d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/google_drive\n"
          ]
        }
      ],
      "source": [
        "# Mounting google drive\n",
        "google_drive_mount_point = '/content/google_drive'\n",
        "\n",
        "import os, sys, time\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount(google_drive_mount_point)\n",
        "\n",
        "if not os.getenv(\"DEBUG\"):\n",
        "    google_drive = google_drive_mount_point + '/My Drive' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_KxNcW2FBHe"
      },
      "source": [
        "## Step 2. Loading and preparing data\n",
        "\n",
        "Now let's read in the reviews and their labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UrzJBGJQCKKh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d76ca966-b255-4afe-f0fd-5ba7cca6c847"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-ad615cd52698>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    \"google_drive/MyDrive/    \"google_drive/MyDrive/Faculty_files/Education/Teaching/LearningProt_2022//dataset/train\",\u001b[0m\n\u001b[0m                                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
        "\n",
        "train_data = text_dataset_from_directory(\n",
        "    \"google_drive/MyDrive/Faculty_files/Education/Teaching/LearningProt_2022//dataset/train\",\n",
        "    batch_size=64\n",
        ")# <-- change the path to location in drive\n",
        "test_data = text_dataset_from_directory(\n",
        "    \"google_drive/MyDrive/    \"google_drive/MyDrive/Faculty_files/Education/Teaching/LearningProt_2022//dataset/train\",\n",
        "/dataset/test\",\n",
        "    batch_size=64\n",
        ")# <-- change the path to location in drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9vBMP3kCVIT"
      },
      "source": [
        "There are some html markups in some of the lines in our data (things like `<br />`). Let's clean-up the data and remove some html markups."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhrDXk-NCc74"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import text_dataset_from_directory\n",
        "from tensorflow.strings import regex_replace\n",
        "\n",
        "def prepareData(dir):\n",
        "  data = text_dataset_from_directory(dir)\n",
        "  return data.map(\n",
        "    lambda text, label: (regex_replace(text, '<br />', ' '), label),\n",
        "  )\n",
        "\n",
        "train_data = prepareData(\n",
        "    'google_drive/MyDrive/.../dataset/train'\n",
        ")# <-- change the path to location in drive (google_drive/MyDrive/...)\n",
        "test_data = prepareData(\n",
        "    'google_drive/MyDrive/.../dataset/test'\n",
        ")# <-- change the path to location in drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aeJDiiLZD2IC"
      },
      "source": [
        "## Step 3. Building your model\n",
        "\n",
        "Now let's build our model. RNN is still a sequential model, but it has some new units that we will be using. Let's walk through them one by one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6Z8FozZEZ9J"
      },
      "source": [
        "### 3.1. Starting the model input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpKZQo60EDFF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import Input\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(1,), dtype=\"string\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEzdkor7EEw_"
      },
      "source": [
        "Input is one string at a time. We take the string, pass it to RNN and predict whether it is a positive or negative review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbb1fDa-EdR4"
      },
      "source": [
        "### 3.2. First layer, text visualization\n",
        "\n",
        "Our first layer will be a [TextVectorization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization), which will process the input string and turn it into a sequence of integers, each one representing a token.\n",
        "\n",
        "For something like a protein string, you won't need this as we only have 20 amino acids and we can one-hot-encode those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gH_uOv4CENp-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "max_tokens = 1000\n",
        "max_len = 100\n",
        "vectorize_layer = TextVectorization(\n",
        "  # Max vocab size. Any words outside of the max_tokens most common ones\n",
        "  # will be treated the same way: as \"out of vocabulary\" (OOV) tokens.\n",
        "  max_tokens=max_tokens,\n",
        "  # Output integer indices, one per string token\n",
        "  output_mode=\"int\",\n",
        "  # Always pad or truncate to exactly this many tokens\n",
        "  output_sequence_length=max_len,\n",
        "  \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOYA9s6RExhu"
      },
      "source": [
        "to initialize the layer, we call adapt. This cell can take up to ~10 min to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKcK-8XfEzad"
      },
      "outputs": [],
      "source": [
        "# Call adapt(), which fits the TextVectorization layer to our text dataset.\n",
        "# This is when the max_tokens most common words (i.e. the vocabulary) are selected.\n",
        "train_texts = train_data.map(lambda text, label: text)\n",
        "vectorize_layer.adapt(train_texts, batch_size=32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8vvt3iSE0n1"
      },
      "source": [
        "now we can add it to our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wn3r3mpE2G5"
      },
      "outputs": [],
      "source": [
        "model.add(vectorize_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XWCich6E4ID"
      },
      "source": [
        "### 3.3. Embedding\n",
        "\n",
        "Our next layer will be an [Embedding layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding), which will turn the integers produced by the previous layer into fixed-length vectors.\n",
        "\n",
        "Note that here, we're performing the embedding on the fly instead of loading GloVe or Word2Vec. For proteins, you can also learn embeddings in a similar way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-mo6tIzFAaP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "# Note that we're using max_tokens + 1 here, since there's an\n",
        "# out-of-vocabulary (OOV) token that gets added to the vocab.\n",
        "model.add(Embedding(max_tokens + 1, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx_Q2MGJFeBp"
      },
      "source": [
        "### 3.4. The recurrent layer\n",
        "\n",
        "For this activity, we will use a [SimpleRNN layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/SimpleRNN)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ncV_BuYcFlSw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import SimpleRNN\n",
        "\n",
        "# 64 is the \"units\" parameter, which is the\n",
        "# dimensionality of the output space.\n",
        "model.add(SimpleRNN(64))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsIp9eCeF0eB"
      },
      "source": [
        "### 3.5. Dense layer\n",
        "\n",
        "Finally, we will add our dense layers. We will be including two layers, one dense of size 64 and one output layer.\n",
        "\n",
        "Try to write it yourself. Remember, we only have two categories: positive or negative review.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNBJM3WZGCNu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7sdQaWmJ-ajp"
      },
      "source": [
        "let's take a look at our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn3y7Fb1-cXJ"
      },
      "outputs": [],
      "source": [
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1. Model architecture\n",
        "\n",
        "Load the architecture of your model."
      ],
      "metadata": {
        "id": "LIccPEEUqJcL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEyCImvYGe93"
      },
      "source": [
        "## Step 4. Compilation\n",
        "\n",
        "Let's compile our model. Try to write the code yourself. Here's a refresher from keras:\n",
        "\n",
        "```\n",
        "compile(\n",
        "    optimizer='rmsprop',\n",
        "    loss=None,\n",
        "    metrics=None,\n",
        "    loss_weights=None,\n",
        "    weighted_metrics=None,\n",
        "    run_eagerly=None,\n",
        "    steps_per_execution=None,\n",
        "    jit_compile=None,\n",
        "    **kwargs\n",
        ")\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "cKRcBsH5qOtA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxqyuc64GwYm",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown Sample code\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss='binary_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ8KIALTG3Fl"
      },
      "source": [
        "## Step 5. Training and evaluation\n",
        "\n",
        "Let's train our model. Because we have lots of training data, this will take some time 5-10 min."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QYJE40YmG4xz"
      },
      "outputs": [],
      "source": [
        "model.fit(train_data, epochs=10, batch_size=64)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2. Model performance\n",
        "\n",
        "What is the accuracy of your model?\n",
        "\n",
        "Run the next cell and see how it works on two test examples."
      ],
      "metadata": {
        "id": "9hzZNIwmqve5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's see how your model works on test data."
      ],
      "metadata": {
        "id": "tg54kQ9jD5lN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LbQ7p1cHbn_",
        "outputId": "0b79c217-1338-4bcc-fcdb-9923552e273b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.74810326]]\n",
            "[[0.25660262]]\n"
          ]
        }
      ],
      "source": [
        "# Should print a very high score like 0.98.\n",
        "print(model.predict([\n",
        "  \"i loved it! highly recommend it to anyone and everyone looking for a great movie to watch.\",\n",
        "]))\n",
        "\n",
        "# Should print a very low score like 0.01.\n",
        "print(model.predict([\n",
        "  \"this was awful! i hated it so much, nobody should watch this. the acting was terrible, the music was terrible, overall it was just bad.\",\n",
        "]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to get the accuracy on your test set based on previous codes you used. Note that test_data includes both X and Y, so you don't need to provide them separately. Since we have lots of test data, let's use `batch_size=32`.\n"
      ],
      "metadata": {
        "id": "i-acXgC-D8Zp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code\n",
        "\n"
      ],
      "metadata": {
        "id": "EzUAFGZtriPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaC_cdUco6Ro"
      },
      "outputs": [],
      "source": [
        "#@markdown Sample code\n",
        "\n",
        "model.evaluate(test_data, batch_size=32)\n",
        "#print('Accuracy: %.2f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3. Model tuning\n",
        "\n",
        "What is the issue with your model? What are possible ways you can fix it?"
      ],
      "metadata": {
        "id": "yBqNPOKPr77F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4. Early stopping\n",
        "\n",
        "Try changing the number of epochs from 10 to 8 and 5. This is called early stopping. What changes do you observe in test/train performance?\n",
        "\n",
        "Note that you need to rebuild your model, otherwise it will continue training (for example if your model had accuracy of 0.8, if you just repeat training, it will start with accuracy of 0.8)"
      ],
      "metadata": {
        "id": "qJyk3Tpruv42"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8lCz9DFHziT"
      },
      "source": [
        "#### Q5. Adding dropouts\n",
        "\n",
        "One way to avoid overfitting is drop-out. Drop-out means that at each round, some percent of neurons are ingonred. This randomness in removing some neurons help prevent the network from memorizing.\n",
        "\n",
        "Try adding drop-out to your model at different percentages (0.1, 0.2). How does that affect your performance?\n",
        "\n",
        "```\n",
        "model.add(SimpleRNN(64, dropout=0.25, recurrent_dropout=0.25))\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "iliSlPBosKpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glzOMuNpHkgI"
      },
      "source": [
        "### Optional. Adding depth\n",
        "\n",
        "Try to make the model deep. To do this, you can add your layers like this:\n",
        "\n",
        "```\n",
        "# Return the full sequence instead of just the last\n",
        "# output of the sequence.\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "\n",
        "# This second recurrent layer's input sequence is the\n",
        "# output sequence of the previous layer.\n",
        "model.add(SimpleRNN(64))\n",
        "```\n",
        "\n",
        "How does this affect your results?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "W5L2_RNNKeras.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3Vjc63u3AorO",
        "O_KxNcW2FBHe",
        "aeJDiiLZD2IC",
        "rEyCImvYGe93",
        "cZ8KIALTG3Fl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}