{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W4L2_CNNKeras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Implementing CNN architecture**\n",
        "<font color='grey' size='1.5'> Created by Parisa Hosseinzadeh for *Machine learning for proteins*, Spring 2022. \n",
        "This notebook is adapted from [Victor Zhou](https://victorzhou.com/blog/keras-cnn-tutorial/), [Jason Brownlee](https://machinelearningmastery.com/how-to-visualize-filters-and-feature-maps-in-convolutional-neural-networks/), and [Rohit Thakur](https://towardsdatascience.com/step-by-step-vgg16-implementation-in-keras-for-beginners-a833c686ae6c).\n",
        "\n",
        "In today's in-class activity, we will be building simple CNN modules for image recognition and will build our way up to more difficult examples."
      ],
      "metadata": {
        "id": "0y8MoqZNwQbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Simple CNN for handwritten digit recognition\n",
        "\n",
        "In the first part of this exercise, we will be building a very simple CNN model to perform predictions on MNIST dataset.\n",
        "\n",
        "A bit about MNIST dataset from [MNIST wikipedia page](https://en.wikipedia.org/wiki/MNIST_database):\n",
        "\n",
        "The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. \n",
        "\n",
        "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png?format=250w\" >"
      ],
      "metadata": {
        "id": "zRVqK0X7w0Xa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Loading and preparing MNIST dataset"
      ],
      "metadata": {
        "id": "vGRddvNeFjj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow numpy mnist"
      ],
      "metadata": {
        "id": "nzCoiSCFFeZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import mnist\n",
        "from tensorflow import keras\n",
        "\n",
        "train_images = mnist.train_images()\n",
        "train_labels = mnist.train_labels()\n",
        "test_images = mnist.test_images()\n",
        "test_labels = mnist.test_labels()\n",
        "\n",
        "# Normalize the images.\n",
        "train_images = (train_images / 255) - 0.5\n",
        "test_images = (test_images / 255) - 0.5\n",
        "\n",
        "# Reshape the images.\n",
        "train_images = np.expand_dims(train_images, axis=3)\n",
        "test_images = np.expand_dims(test_images, axis=3)\n",
        "\n",
        "print(train_images.shape) \n",
        "print(test_images.shape)  "
      ],
      "metadata": {
        "id": "eSXCjkU3Fmr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1. Size and shape of data\n",
        "\n",
        "Based on the numbers above, answer question 1:\n",
        "\n",
        "1. How many training data you have? \n",
        "2. How many test data you have?\n",
        "3. What is the shape of data? (pixels/colors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V9MK8Qi6iT6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. Building the model\n",
        "\n",
        "Similar to a fully connected ANN, a CNN is also a *sequential* model. \n",
        "\n",
        "We will be using **Conv2D** and **MaxPooling2D** from keras to build this model and we add at the end a **Dense** layer for prediction. See the architecture below:\n",
        "\n",
        "<img src=\"https://victorzhou.com/media/cnn-post/cnn-dims-3.svg\">\n",
        "\n",
        "\n",
        "\n",
        "Let's give it a try."
      ],
      "metadata": {
        "id": "n0vHOiDKF7ln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Importing necessary modules"
      ],
      "metadata": {
        "id": "c3_1CDOwGggN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "1nRTE41tGjHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Setting up parameters"
      ],
      "metadata": {
        "id": "iCj_zWnpGk9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_filters = 8 # we choose to use 8 filters to check 8 features\n",
        "filter_size = 3 # our filters are 3x3\n",
        "pool_size = 2 #our maxpool is 2x2"
      ],
      "metadata": {
        "id": "xKMIfSJHGnH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Building the model"
      ],
      "metadata": {
        "id": "VnskN9j7HBfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keras sequential model\n",
        "model = Sequential()\n",
        "# Build the convolution layer\n",
        "# The input dimension is the number of your features.\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        num_filters, # number of filters\n",
        "        filter_size, # size of filter\n",
        "        input_shape=(28, 28, 1), #input image size, printed above\n",
        "        strides=1,\n",
        "        padding='valid',\n",
        "        activation='relu',\n",
        "    )\n",
        ")\n",
        "# add the maxpooling layer\n",
        "model.add(\n",
        "    MaxPooling2D(pool_size=pool_size)\n",
        ")\n",
        "# flatten (you need to flatten so that \n",
        "# everything is a vector to feed into dense layer)\n",
        "model.add(Flatten())\n",
        "# Add a dense layer for prediction\n",
        "model.add(\n",
        "    Dense(\n",
        "         , # number of neurons\n",
        "        activation= #activation\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "zTQ4GvAdFu8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2. Output layer\n",
        "\n",
        "Based on the dataset (and the image above), what should be the number of neurons for your final layer? What activation function will you pick?"
      ],
      "metadata": {
        "id": "819bUqCli3lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at your model:"
      ],
      "metadata": {
        "id": "EZpucZMRIj-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install keras-visualizer"
      ],
      "metadata": {
        "id": "_YZgt5j4IQ_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_visualizer import visualizer \n",
        "from IPython.display import Image\n",
        "\n",
        "visualizer(model, format='png', view=True)\n",
        "Image('graph.png')"
      ],
      "metadata": {
        "id": "ZR2pOK9nIXJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3. Upload model photo\n",
        "\n",
        "This model photo is saved to your drive. Upload it to your question."
      ],
      "metadata": {
        "id": "ZYHF4VL5jLj_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3. Compiling your model\n",
        "\n",
        "Let's now compile the model. Try running the code yourself using what we used before for [ANNs](https://colab.research.google.com/drive/1Co5QuNEVsSIccx-dL6fGh2OTYok9fXYT?usp=sharing). Note that because we have more than one category, the loss will be **categorical_crossentropy** instead of binary_crossentropy."
      ],
      "metadata": {
        "id": "e-LI7LfEIwDP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")"
      ],
      "metadata": {
        "id": "ndxDAECMJEUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4. Training\n",
        "\n",
        "Now let's train our model."
      ],
      "metadata": {
        "id": "iZny2-oYJGSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# let's check some of our labels\n",
        "\n",
        "print(train_labels[0:5])"
      ],
      "metadata": {
        "id": "9NHD_Z58JMlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you remember, the categories need to be one-hot encoded. Let's try to do that and see how they look like."
      ],
      "metadata": {
        "id": "qDjvg2ttJUU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(to_categorical(train_labels[0:5]))"
      ],
      "metadata": {
        "id": "zTmaYl92Jas1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "id": "fxoiomI7Jjd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5. Evaluation\n",
        "\n",
        "Let's evaluate the model's performance on your test set."
      ],
      "metadata": {
        "id": "jVRmEB3iiIn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the first 5 test images.\n",
        "predictions = model.predict(test_images[:5])\n",
        "\n",
        "# Print our model's predictions.\n",
        "print(np.argmax(predictions, axis=1)) # [7, 2, 1, 0, 4]\n",
        "# Check our predictions against the ground truths.\n",
        "print(test_labels[:5]) # [7, 2, 1, 0, 4]"
      ],
      "metadata": {
        "id": "sSHC4Uw0iMgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4. Accuracy on test\n",
        "\n",
        "What is accuracy on test model? You can check how to calcualte it from [ANN code](https://colab.research.google.com/drive/1Co5QuNEVsSIccx-dL6fGh2OTYok9fXYT?usp=sharing)."
      ],
      "metadata": {
        "id": "6pYMLc4JjZ17"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "6OEzyXmujl5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample solution\n",
        "\n",
        "_, accuracy = model.evaluate(test_images, to_categorical(test_labels))\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4CIgwbmyiRkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q5. Changing number of filters\n",
        "\n",
        "In the code above, try to change number of filters from 8 to something else. Maybe 16. What do you observe in terms of performance (speed and accurcay)?"
      ],
      "metadata": {
        "id": "ujB4dJkgmzys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. Adding more layers\n",
        "\n",
        "Try adding another convolutional layer and re-running your model. How does the accuracy change?"
      ],
      "metadata": {
        "id": "Zop2WBaAk4CE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "k4pBjgMslyyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample solution\n",
        "\n",
        "# define the keras sequential model\n",
        "model = Sequential()\n",
        "# Build the convolution layer\n",
        "# The input dimension is the number of your features.\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        num_filters, # number of filters\n",
        "        filter_size, # size of filter\n",
        "        input_shape=(28, 28, 1), #input image size, printed above\n",
        "        strides=1,\n",
        "        padding='valid',\n",
        "        activation='relu',\n",
        "    )\n",
        ")\n",
        "#add second convolution\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        num_filters, # number of filters\n",
        "        filter_size, # size of filter\n",
        "        input_shape=(28, 28, 1), #input image size, printed above\n",
        "        strides=1,\n",
        "        padding='valid',\n",
        "        activation='relu',\n",
        "    )\n",
        ")\n",
        "# add the maxpooling layer\n",
        "model.add(\n",
        "    MaxPooling2D(pool_size=pool_size)\n",
        ")\n",
        "# flatten (you need to flatten so that \n",
        "# everything is a vector to feed into dense layer)\n",
        "model.add(Flatten())\n",
        "# Add a dense layer for prediction\n",
        "model.add(\n",
        "    Dense(\n",
        "        10 , # number of neurons\n",
        "        activation='sigmoid' #activation\n",
        "    )\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "  'adam',\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")\n",
        "\n",
        "_, accuracy = model.evaluate(test_images, to_categorical(test_labels))\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hDyQBG9zlz0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6. Check filters and feature maps\n",
        "\n",
        "Now let's take a look at what our filters are learning and how are feature maps look like."
      ],
      "metadata": {
        "id": "UA6VzEbticwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize filter shapes\n",
        "for layer in model.layers:\n",
        "\t# check for convolutional layer\n",
        "\tif 'conv' not in layer.name:\n",
        "\t\tcontinue\n",
        "\t# get filter weights\n",
        "\tfilters, biases = layer.get_weights()\n",
        "\tprint(layer.name, filters.shape)"
      ],
      "metadata": {
        "id": "tDXPjKVEi5si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve weights from the second hidden layer\n",
        "filters, biases = model.layers[0].get_weights()\n",
        "\n",
        "# normalize filter values to 0-1 so we can visualize them\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "#let's see how many filters we have\n",
        "print('number of filters is {}'.format(len(filters)))\n",
        "\n",
        "# let's take a look at one of our convolution filters\n",
        "# These are the kernels you manually set in in-class activity\n",
        "# last lecture\n",
        "print(filters[0])"
      ],
      "metadata": {
        "id": "FlGZto3RjB9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plot first few filters\n",
        "n_filters, ix = 3, 1\n",
        "for i in range(n_filters):\n",
        "\t# get the filter\n",
        "\tf = filters[:, :, :, i]\n",
        "\t# plot each channel separately\n",
        "\t# specify subplot and turn of axis\n",
        "\tax = plt.subplot(n_filters, 3, ix)\n",
        "\tax.set_xticks([])\n",
        "\tax.set_yticks([])\n",
        "\t# plot filter channel in grayscale\n",
        "\tplt.imshow(f[:, :, 0], cmap='gray')\n",
        "\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DnDeZdsfjG3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "# redefine model to output right after the first hidden layer\n",
        "model = Model(inputs=model.inputs, outputs=model.layers[0].output)"
      ],
      "metadata": {
        "id": "d8UZwC6bCDuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get feature map for first hidden layer\n",
        "feature_maps = model.predict(test_images[:1])"
      ],
      "metadata": {
        "id": "g5_ekSOpCRYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot all 64 maps in an 8x8 squares\n",
        "square1 = 4\n",
        "square2 = 2\n",
        "ix = 1\n",
        "for _ in range(square1):\n",
        "\tfor _ in range(square2):\n",
        "\t\t# specify subplot and turn of axis\n",
        "\t\tax = plt.subplot(square1, square2, ix)\n",
        "\t\tax.set_xticks([])\n",
        "\t\tax.set_yticks([])\n",
        "\t\t# plot filter channel in grayscale\n",
        "\t\tplt.imshow(feature_maps[0, :, :, ix-1], cmap='gray')\n",
        "\t\tix += 1\n",
        "# show the figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Mjf5CCYXC1AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q7. Feature maps and filters\n",
        "\n",
        "What did you notice after running the cells above?"
      ],
      "metadata": {
        "id": "E0huyst2nQW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. VGG16\n",
        "\n",
        "Now let's take it a step further and implement VGG16. If you remember from lecture, VGG looks like this:\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/940/1*3-TqqkRQ4rWLOMX-gvkYwA.png\">\n",
        "\n",
        "We will be using keras to implement a smaller version of VGG to run on MNISt data."
      ],
      "metadata": {
        "id": "ipuQ32GWDepU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1. Setting up for the run\n",
        "\n",
        "Let's import all necessary modules."
      ],
      "metadata": {
        "id": "mGn19S1kHTL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras,os\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "oOuC53yMD12q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2. Building the model\n",
        "\n",
        "Below is the code that builds a VGG-like model for our datasets."
      ],
      "metadata": {
        "id": "lXSr40WEHxYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        input_shape=(28,28,1),\n",
        "        filters=64,\n",
        "        kernel_size=(3,3),\n",
        "        padding=\"same\", \n",
        "        activation=\"relu\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        filters=128, \n",
        "        kernel_size=(3,3), \n",
        "        padding=\"same\", \n",
        "        activation=\"relu\"\n",
        "    )\n",
        ")\n",
        "\n",
        "\n",
        "model.add(\n",
        "    MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        filters=256, \n",
        "        kernel_size=(3,3), \n",
        "        padding=\"same\", \n",
        "        activation=\"relu\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    Conv2D(\n",
        "        filters=256, \n",
        "        kernel_size=(3,3), \n",
        "        padding=\"same\", \n",
        "        activation=\"relu\"\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    MaxPool2D(\n",
        "        pool_size=(2,2),\n",
        "        strides=(2,2)\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    MaxPool2D(\n",
        "        pool_size=(3,3)\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=512,activation=\"relu\"))\n",
        "model.add(Dense(units=512,activation=\"relu\"))\n",
        "model.add(Dense(units=10, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "tu3vroGdHzCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q8. Size of the model\n",
        "\n",
        "Based on the model above and our input data, can we add more CNN + pooling layers?"
      ],
      "metadata": {
        "id": "7FCEHhg0nj3h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ulpWqDrSIyXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "9vSzYrugIzIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_visualizer import visualizer \n",
        "from IPython.display import Image\n",
        "\n",
        "visualizer(model, format='png', view=True)\n",
        "Image('graph.png')"
      ],
      "metadata": {
        "id": "Y0_BxayPe3sV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "  train_images,\n",
        "  to_categorical(train_labels),\n",
        "  epochs=3,\n",
        "  validation_data=(test_images, to_categorical(test_labels)),\n",
        ")"
      ],
      "metadata": {
        "id": "kg338yZaJ_bY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q9. Accuracy\n",
        "\n",
        "What is the accuracy of your VGG model? How do you compare the overall performance (accuracy/speed) of VGG and your simpler CNN?"
      ],
      "metadata": {
        "id": "V6PTE9a0n-PN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Nk4eq1qqoR_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "PAMcLa4MoHVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown sample solution\n",
        "\n",
        "_, accuracy = model.evaluate(test_images, to_categorical(test_labels))\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "opojI_vaKXLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optional ResNet\n",
        "\n",
        "Try to see if you can build ResNet. Check [this blog](https://machinelearningknowledge.ai/keras-implementation-of-resnet-50-architecture-from-scratch/) for step-by-step of code addition. \n",
        "\n",
        "For such well-known models, there is an easier way too. Check [this blog](https://towardsdatascience.com/understanding-and-coding-a-resnet-in-keras-446d7ff84d33) for a guide to an easy solution. As you can see, for pretrained models, you can easily use pre-built models."
      ],
      "metadata": {
        "id": "f3DWvyAIojoW"
      }
    }
  ]
}