{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "W3L2_KerasANN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Building a fully connected deep neural net with Keras**\n",
        "<font color='grey' size='1.5'> Created by Parisa Hosseinzadeh for *Machine learning for proteins*, Spring 2022. This notebook is adapted from [Jason Brownlee](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/).\n",
        "\n",
        "Today, we will work on developing a fully connected deep neural net using [keras](https://keras.io/) to perform classification on *Pima Indians diabetes* set from [Kaggle](https://www.kaggle.com/datasets/kumargh/pimaindiansdiabetescsv?resource=download), the same one we used for our random forest classifier building. \n",
        "\n",
        "Here is the description of the dataset from the website:\n",
        "\n",
        "This dataset describes the medical records for Pima Indians\n",
        "and whether or not each patient will have an onset of diabetes within \fve years.\n",
        "\n",
        "Fields description follow:\n",
        "\n",
        "- **preg** = Number of times pregnant\n",
        "- **plas** = Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "- **pres** = Diastolic blood pressure (mm Hg)\n",
        "- **skin** = Triceps skin fold thickness (mm)\n",
        "- **test** = 2-Hour serum insulin (mu U/ml)\n",
        "- **mass** = Body mass index (weight in kg/(height in m)^2)\n",
        "- **pedi** = Diabetes pedigree function\n",
        "- **age** = Age (years)\n",
        "- **class** = Class variable (1:tested positive for diabetes, 0: tested negative for diabetes)\n",
        "\n"
      ],
      "metadata": {
        "id": "xAMFXTjH5nA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing to run"
      ],
      "metadata": {
        "id": "2FDTgKZM901u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and installing necessary modules"
      ],
      "metadata": {
        "id": "6cyJJi9N92yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install keras-visualizer"
      ],
      "metadata": {
        "id": "6XthyYoJ96Zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ijtq0us5Ysj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "9b1ae94b-e759-4d80-d89d-02244bd27333"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f2f61697391c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_visualizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_visualizer'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "# first neural network with keras tutorial\n",
        "from numpy import loadtxt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras_visualizer import visualizer \n",
        "from IPython.display import Image\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and preparing the dataset\n",
        "\n",
        "We will use loadtxt module from numpy to load in our dataset. But before that, let's take a look at the dataframe to see how it looks like."
      ],
      "metadata": {
        "id": "LV32SjIM-ECH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the dataset does not have column names\n",
        "# defining features/column names\n",
        "features = ['preg','plas','pres','skin',\n",
        "            'test','mass','pedi','age',\n",
        "            'class']\n",
        "# loading the dataset\n",
        "data = pd.read_csv('pima-indians-diabetes.csv', \n",
        "                   header=None,\n",
        "                   names=features)\n",
        "# viewing the top 5 rows\n",
        "data.head()"
      ],
      "metadata": {
        "id": "TDxmZ2OK-UAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the first 8 columns are the features and the last one is the lables. \n",
        "\n",
        "Let's now use loadtxt to load our dataset into a numpy array."
      ],
      "metadata": {
        "id": "OUHcd-oO-elF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "# if you open csv, you can see that ',' is used to separate columns\n",
        "# that's why we use ',' as delimiter.\n",
        "dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')"
      ],
      "metadata": {
        "id": "w-LORmgm6P9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at our dataset\n",
        "dataset"
      ],
      "metadata": {
        "id": "WvD2tvWd-xzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the dataset is a matrix (array of arrays). Each row is one input. Columns define features and the last column is our label.\n",
        "\n",
        "Define X and y. X is all the rows and the first 8 column. y is all the rows and the last column. Remember that in python, numbering always start at 0."
      ],
      "metadata": {
        "id": "WVcJFFxN-2GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split into input (X) and output (y) variables\n",
        "X = \n",
        "y = "
      ],
      "metadata": {
        "id": "__V6SUmn_KDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample answer\n",
        "\n",
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "metadata": {
        "id": "IN0U8ZcM-wLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's take a look at the distribution of labels\n",
        "plt.hist(y)"
      ],
      "metadata": {
        "id": "Ed6fhiZv6oPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two labels seem to be in the same ballpark. Let's use [train-test split from scikit learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to generate our training set and test set. Let's keep 10% of data in the test set."
      ],
      "metadata": {
        "id": "g6m9TAm2_TLG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the function\n",
        "\n",
        "# define the split\n",
        "X_train, X_test, y_train, y_test ="
      ],
      "metadata": {
        "id": "nduIK74j_6CG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample code\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "     X, y, test_size=0.1, random_state=42)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ttKa36Br_tH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "The model we are building today is a fully connected dense layer with two hidden layers. The first layer has 12 neurons and the other one has 8 neurons. The output layer has a size of 1 because we're performing a binary classification.\n",
        "\n",
        "If you remember from class, we use `relu` for all activation functions except for the output layer that uses `sigmoid`. Let's build our sequential model. Sequential means the output of each layer is the input of the next.\n"
      ],
      "metadata": {
        "id": "5xB9Gf0xAAdA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a model"
      ],
      "metadata": {
        "id": "NW8-QdSyBAPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define the keras model\n",
        "model = Sequential()\n",
        "# Build 3 layers of size 12, 8 and 1.\n",
        "# The input dimension is the number of your features.\n",
        "model.add(Dense( , #add number of neurons\n",
        "                input_dim= , #add inout dimension\n",
        "                activation='') #add activation function\n",
        "          )\n",
        "# add the second dense layer.\n",
        "# Note that no dimension for the remaining layers\n",
        "model.add(Dense( , # add number of neurons\n",
        "                activation='') #add activation function\n",
        "          )\n",
        "# add your output layer\n",
        "model.add(Dense( , # number of nodes\n",
        "                activation=''))#add activation function"
      ],
      "metadata": {
        "id": "pcg3rTL3DnEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample answer\n",
        "\n",
        "# define the keras model\n",
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=8, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "yB7XbXsB6vrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at our model. We can look at it in a sequential way."
      ],
      "metadata": {
        "id": "8w8zEYMMAslJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "9jdS98BH772Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cell below helps you visualize your model in a more graphic way."
      ],
      "metadata": {
        "id": "kOu2vpwiA05X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "visualizer(model, format='png', view=True)\n",
        "Image('graph.png')"
      ],
      "metadata": {
        "id": "A4IUSWSS8r6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q1. Time to exercise\n",
        "\n",
        "Load your network model (it is saved as graph.png) onto the in-class activity."
      ],
      "metadata": {
        "id": "TAKI4ov-IAoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model\n",
        "\n",
        "Now that we have set the network architecture, we need to define the details of the model, things like the loss and the optimizer.\n",
        "\n",
        "If you remember, we use corss-entropy as a loss function for binary classification and `adam` is almost always the best first choice for your optimizer."
      ],
      "metadata": {
        "id": "cpq6PiVyA9dr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the keras model\n",
        "model.compile(loss='', # choose your loss from https://keras.io/api/losses/\n",
        "              optimizer='', # define optimizer\n",
        "              metrics=['accuracy']) # we want to see accuracy"
      ],
      "metadata": {
        "id": "z7Q2rnppELxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample code\n",
        "# compile the keras model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PQUqW0Qc60U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fitting\n",
        "\n",
        "The next step is to fit your model to your train set.\n",
        "\n",
        "We use epoch number of 150 and batch size of 10 for now."
      ],
      "metadata": {
        "id": "jNfK14-HEan7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit( , # input data\n",
        "           , # labels\n",
        "          epochs=150, \n",
        "          batch_size=10)"
      ],
      "metadata": {
        "id": "f0W0vKg-FkPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample code\n",
        "# fit the keras model on the dataset\n",
        "model.fit(X_train, y_train, epochs=150, batch_size=10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7agoACEd61z5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation\n",
        "\n",
        "Let's first check the accuracy of our model."
      ],
      "metadata": {
        "id": "AqNqnhMwF0Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, accuracy = model.evaluate(X, y)\n",
        "print('Accuracy: %.2f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "KmPJ3Vue7JUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q2. Time to exercise\n",
        "\n",
        "1. What is the accuracy you obtained?\n",
        "2. How is it compared to your random forest and your gradient boosting?"
      ],
      "metadata": {
        "id": "QuseBE9LINxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's predict the test set values."
      ],
      "metadata": {
        "id": "fZcWZujLF7HT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make probability predictions with the model\n",
        "predictions = model.predict() # add test inputs"
      ],
      "metadata": {
        "id": "CRcp_wLMGByU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample code\n",
        "# make probability predictions with the model\n",
        "predictions = model.predict(X_test)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "KNpjGToO7LXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# taking a look at 10 first predictions\n",
        "predictions[:10]"
      ],
      "metadata": {
        "id": "9cvDN9W8GLS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, predictions are probabilities. We need to change them to 0/1 using a threshold (often 0.5).\n",
        "\n",
        "Try to generate a predictions list that is just 0 or 1 from the list above."
      ],
      "metadata": {
        "id": "yEMtDR2rGJmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = "
      ],
      "metadata": {
        "id": "g-K42L6FGg96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Sample code\n",
        "\n",
        "# round predictions \n",
        "rounded = [round(x[0]) for x in predictions]\n",
        "# make class predictions with the model\n",
        "predictions = (model.predict(X) > 0.5).astype(int)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PqMZo1z8GiNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look to see if it's working."
      ],
      "metadata": {
        "id": "BNsQH2nhGp31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[:10]"
      ],
      "metadata": {
        "id": "7TWoSUGHGpYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's try to see how well your model is working."
      ],
      "metadata": {
        "id": "Warw-6BXGtkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#looking at first 10 predictions\n",
        "for i in range(10):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
      ],
      "metadata": {
        "id": "mjY61zR4Gyi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Practice\n",
        "\n",
        "#### Q3. Calculate accuracy on the test set."
      ],
      "metadata": {
        "id": "fp-Mvve3G9Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "6yPTpXcDHKRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q4. Plot a confusion matrix on test set\n",
        "\n",
        "[Here's](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62) a refresher on confusion matrices. You can use [scikit](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html) to generate the confusion matrix."
      ],
      "metadata": {
        "id": "wKGLp4e6HJjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code"
      ],
      "metadata": {
        "id": "kBBr8H3NIbqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Post-class assignment\n",
        "\n",
        "Try changing the network architecture/parameters to improve your model. \n",
        "\n",
        "What is the best accuracy that you get? What is the final best model?"
      ],
      "metadata": {
        "id": "qKfbSIlmHrHQ"
      }
    }
  ]
}